<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Lorenzo Pacchiardi </title> <meta name="author" content="Lorenzo Pacchiardi"> <meta name="description" content="Lorenzo Pacchiardi, Research Associate at the Center for the Future of Intelligence, University of Cambridge. "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%91%A8%E2%80%8D%F0%9F%92%BB&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="http://lorenzopacchiardi.me//"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js?bf50d6d9dd867d3e0f3b0add94449649"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <div class="navbar-brand social"> <a href="mailto:%6C%70%36%36%36@%63%61%6D.%61%63.%75%6B" title="email"><i class="fa-solid fa-envelope"></i></a> <a href="https://orcid.org/0000-0003-4760-7638" title="ORCID" rel="external nofollow noopener" target="_blank"><i class="ai ai-orcid"></i></a> <a href="https://scholar.google.com/citations?user=9EAb0uEAAAAJ" title="Google Scholar" rel="external nofollow noopener" target="_blank"><i class="ai ai-google-scholar"></i></a> <a href="https://github.com/LoryPack" title="GitHub" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-github"></i></a> <a href="https://www.linkedin.com/in/lorenzo-pacchiardi" title="LinkedIn" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-linkedin"></i></a> <a href="https://twitter.com/LPacchiardi" title="X" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-x-twitter"></i></a> </div> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item active"> <a class="nav-link" href="/">about <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/talks/">talks </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/resources/">resources </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fa-solid fa-moon"></i> <i class="fa-solid fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title"> <span class="font-weight-bold">Lorenzo</span> Pacchiardi </h1> <p class="desc"></p> </header> <article> <div class="profile float-right"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/prof_pic-480.webp 480w,/assets/img/prof_pic-800.webp 800w,/assets/img/prof_pic-1400.webp 1400w," sizes="(min-width: 800px) 231.0px, (min-width: 576px) 30vw, 95vw" type="image/webp"> <img src="/assets/img/prof_pic.jpg?ebed4ec7ffbef62222a1c9bdc058971f" class="img-fluid z-depth-1 rounded" width="100%" height="auto" alt="prof_pic.jpg" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div class="clearfix"> <p><em>Assistant Research Professor, University of Cambridge</em></p> <p>I am an Assistant Research Professor at the <a href="http://lcfi.ac.uk/" rel="external nofollow noopener" target="_blank">Leverhulme Centre for the Future of Intelligence</a> at the University of Cambridge. I lead a research project (funded by <a href="https://www.openphilanthropy.org/" rel="external nofollow noopener" target="_blank">Open Philanthropy</a>) on developing a benchmark for measuring the ability of LLMs to perform data science tasks. I am more broadly interested in <a href="https://arxiv.org/abs/2502.15620" rel="external nofollow noopener" target="_blank">AI evaluation</a>, particularly in <a href="https://arxiv.org/abs/2502.14445" rel="external nofollow noopener" target="_blank">predictability</a> and <a href="https://arxiv.org/abs/2503.06378" rel="external nofollow noopener" target="_blank">cognitive evaluation</a>, and I closely collaborate with <a href="http://josephorallo.webs.upv.es/" rel="external nofollow noopener" target="_blank">Prof Jos√© Hern√°ndez-Orallo</a> and <a href="http://lcfi.ac.uk/people/lucy-cheke/" rel="external nofollow noopener" target="_blank">Prof Lucy Cheke</a>. I contribute to the <a href="https://aievaluation.substack.com/" rel="external nofollow noopener" target="_blank">AI evaluation newsletter</a>.</p> <p>I am deeply familiar with EU AI policy (having been involved in several initiatives), and am one of the co-founders of the Italian AI policy think tank <a href="https://www.cepte.it/" rel="external nofollow noopener" target="_blank">CePTE</a>. I also collaborate with <a href="https://www.unjournal.org/" rel="external nofollow noopener" target="_blank">The Unjournal</a> to make impactful research more rigorous, and I co-founded <a href="https://academicjobsitaly.com/" rel="external nofollow noopener" target="_blank">AcademicJobsItaly.com</a> to make the Italian academic job market more accessible.</p> <p>I previously worked on <a href="https://arxiv.org/abs/2309.15840" rel="external nofollow noopener" target="_blank">detecting lying in large language models</a> with <a href="https://owainevans.github.io/" rel="external nofollow noopener" target="_blank">Dr Owain Evans</a> (through the MATS programme) and on <a href="https://artificialintelligenceact.eu/standard-setting/" rel="external nofollow noopener" target="_blank">technical standards for AI</a> for the <a href="https://artificialintelligenceact.eu/" rel="external nofollow noopener" target="_blank">EU AI Act</a> at the <a href="https://futureoflife.org/" rel="external nofollow noopener" target="_blank">Future of Life Institute</a>. I have also shortly advised <a href="https://www.rand.org/" rel="external nofollow noopener" target="_blank">RAND</a> on AI evaluation.</p> <p>I obtained a PhD in Statistics and Machine Learning at Oxford, during which I worked on Bayesian simulation-based inference, generative models and probabilistic forecasting (with applications to meteorology). My supervisors were Prof. <a href="https://warwick.ac.uk/fac/sci/statistics/staff/academic-research/dutta/" rel="external nofollow noopener" target="_blank">Ritabrata Dutta</a> (Uni. Warwick) and Prof. <a href="https://www.stats.ox.ac.uk/people/geoff-nicholls" rel="external nofollow noopener" target="_blank">Geoff Nicholls</a> (Uni. Oxford).</p> <p>Before my PhD studies, I obtained a Bachelor‚Äôs degree in Physical Engineering from Politecnico di Torino (Italy) and an MSc in Physics of Complex Systems from Politecnico di Torino and Universit√© Paris-Sud, France. I did my MSc thesis at <a href="https://lighton.ai/" rel="external nofollow noopener" target="_blank">LightOn</a>, a machine learning startup in Paris.</p> </div> <h2> <a href="/news/" style="color: inherit">news</a> </h2> <div class="news"> <div class="table-responsive" style="max-height: 60vw"> <table class="table table-sm table-borderless"> <tr> <th scope="row" style="width: 20%">May 16, 2025</th> <td> Our <a href="https://ai-evaluation-paradigms.github.io/" rel="external nofollow noopener" target="_blank">survey on AI evaluation</a> was accepted at <a href="https://2025.ijcai.org/" rel="external nofollow noopener" target="_blank">IJCAI 2025 survey track</a> and our <a href="https://predictaboard.github.io/" rel="external nofollow noopener" target="_blank">PredictaBoard</a> was accepted at ACL 2025 Findings. <img class="emoji" title=":tada:" alt=":tada:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f389.png" height="20" width="20"> </td> </tr> <tr> <th scope="row" style="width: 20%">Mar 11, 2025</th> <td> Our new <a href="https://arxiv.org/abs/2503.06378" rel="external nofollow noopener" target="_blank">preprint</a> shows how to extract the most predictive and explanatory power from AI benchmarks by automatically annotating the demands posed by each question. Check it out! </td> </tr> <tr> <th scope="row" style="width: 20%">Feb 21, 2025</th> <td> Two new arXiv preprints:<br> <a href="https://ai-evaluation-paradigms.github.io/" rel="external nofollow noopener" target="_blank">one</a> surveying AI evaluation and identifying six main paradigms, <a href="https://predictaboard.github.io/" rel="external nofollow noopener" target="_blank">the other one</a> introducing a benchmark for jointly evaluating the performance of LLMs and its predictability on individual instances. </td> </tr> <tr> <th scope="row" style="width: 20%">Jan 15, 2025</th> <td> Our survey paper <a href="https://openreview.net/forum?id=MB0TCLfLn1" rel="external nofollow noopener" target="_blank">‚ÄúMeasuring Data Science Automation: A Survey of Evaluation Tools for AI Assistants and Agents‚Äù</a> has been accepted and published in <a href="https://www.jmlr.org/tmlr/" rel="external nofollow noopener" target="_blank">Transactions on Machine Learning Research</a>! üéâ </td> </tr> <tr> <th scope="row" style="width: 20%">Oct 15, 2024</th> <td> We have two new preprints on arXiv! <a href="https://arxiv.org/abs/2409.03563" rel="external nofollow noopener" target="_blank">One</a> on predicting the performance of LLMs on individual instances, <a href="https://arxiv.org/abs/2410.11672" rel="external nofollow noopener" target="_blank">the other one</a> on predicting the answers of LLM benchmarks from simple features. </td> </tr> </table> </div> </div> <h2> <a href="/publications/" style="color: inherit">selected publications</a> </h2> <div class="publications"> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge">arXiv</abbr> </div> <div id="cencerrado2025noanswer" class="col-sm-8"> <div class="title">No Answer Needed: Predicting LLM Answer Accuracy from Question-Only Linear Probes</div> <div class="author"> Iv√°n Vicente Moreno Cencerrado ,¬† Arnau Padr√©s Masdemont ,¬† Anton Gonzalvez Hawthorne ,¬† David Demitri Africa ,¬† and¬† <em>Lorenzo Pacchiardi</em> </div> <div class="periodical"> <em>arXiv preprint arXiv:2509.10625</em>, 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://arxiv.org/abs/2509.10625" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="https://github.com/ivanvmoreno/correctness-model-internals" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="abstract hidden"> <p>Do large language models (LLMs) anticipate when they will answer correctly? To study this, we extract activations after a question is read but before any tokens are generated, and train linear probes to predict whether the model‚Äôs forthcoming answer will be correct. Across three open-source model families ranging from 7 to 70 billion parameters, projections on this "in-advance correctness direction" trained on generic trivia questions predict success in distribution and on diverse out-of-distribution knowledge datasets, outperforming black-box baselines and verbalised predicted confidence. Predictive power saturates in intermediate layers, suggesting that self-assessment emerges mid-computation. Notably, generalisation falters on questions requiring mathematical reasoning. Moreover, for models responding "I don‚Äôt know", doing so strongly correlates with the probe score, indicating that the same direction also captures confidence. By complementing previous results on truthfulness and other behaviours obtained with probes and sparse auto-encoders, our work contributes essential findings to elucidate LLM internals.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">cencerrado2025noanswer</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{{No Answer Needed: Predicting LLM Answer Accuracy from Question-Only Linear Probes}}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Cencerrado, Iv√°n Vicente Moreno and Masdemont, Arnau Padr√©s and Hawthorne, Anton Gonzalvez and Africa, David Demitri and Pacchiardi, Lorenzo}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
  <span class="na">eprint</span> <span class="p">=</span> <span class="s">{2509.10625}</span><span class="p">,</span>
  <span class="na">archiveprefix</span> <span class="p">=</span> <span class="s">{arXiv}</span><span class="p">,</span>
  <span class="na">primaryclass</span> <span class="p">=</span> <span class="s">{cs.CL}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{arXiv preprint arXiv:2509.10625}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://arxiv.org/abs/2509.10625}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge">TMLR</abbr> </div> <div id="testini2025measuringdatascienceautomation" class="col-sm-8"> <div class="title">Measuring Data Science Automation: A Survey of Evaluation Tools for AI Assistants and Agents</div> <div class="author"> Irene Testini* ,¬† Jos√© Hern√°ndez-Orallo ,¬† and¬† <em>Lorenzo Pacchiardi*</em> </div> <div class="periodical"> <em>Transactions on Machine Learning Research</em>, 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://openreview.net/forum?id=MB0TCLfLn1" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="abstract hidden"> <p>Data science aims to extract insights from data to support decision-making processes. Recently, Large Language Models (LLMs) are increasingly used as assistants for data science, by suggesting ideas, techniques and small code snippets, or for the interpretation of results and reporting. Proper automation of some data-science activities is now promised by the rise of LLM agents, i.e., AI systems powered by an LLM equipped with additional affordances‚Äîsuch as code execution and knowledge bases‚Äîthat can perform self-directed actions and interact with digital environments. In this paper, we survey the evaluation of LLM assistants and agents for data science. We find (1) a dominant focus on a small subset of goal-oriented activities, largely ignoring data management and exploratory activities; (2) a concentration on pure assistance or fully autonomous agents, without considering intermediate levels of human-AI collaboration; and (3) an emphasis on human substitution, therefore neglecting the possibility of higher levels of automation thanks to task transformation.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">testini2025measuringdatascienceautomation</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{{Measuring Data Science Automation: A Survey of Evaluation Tools for AI Assistants and Agents}}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Testini*, Irene and Hern√°ndez-Orallo, Jos√© and Pacchiardi*, Lorenzo}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Transactions on Machine Learning Research}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{2835-8856}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://openreview.net/forum?id=MB0TCLfLn1}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge">arXiv</abbr> </div> <div id="zhou2025generalscalesunlockai" class="col-sm-8"> <div class="title">General Scales Unlock AI Evaluation with Explanatory and Predictive Power</div> <div class="author"> Lexin Zhou ,¬† <em>Lorenzo Pacchiardi</em> ,¬† Fernando Mart√≠nez-Plumed ,¬† Katherine M. Collins ,¬† Yael Moros-Daval ,¬† Seraphina Zhang ,¬† Qinlin Zhao ,¬† Yitian Huang ,¬† Luning Sun ,¬† Jonathan E. Prunty ,¬† Zongqian Li ,¬† Pablo S√°nchez-Garc√≠a ,¬† Kexin Jiang Chen ,¬† Pablo A. M. Casares ,¬† Jiyun Zu ,¬† John Burden ,¬† Behzad Mehrbakhsh ,¬† David Stillwell ,¬† Manuel Cebrian ,¬† Jindong Wang ,¬† Peter Henderson ,¬† Sherry Tongshuang Wu ,¬† Patrick C. Kyllonen ,¬† Lucy Cheke ,¬† Xing Xie ,¬† and¬† Jos√© Hern√°ndez-Orallo </div> <div class="periodical"> <em>arXiv preprint arXiv:2503.06378</em>, 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://kinds-of-intelligence-cfi.github.io/ADELE/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="https://github.com/Kinds-of-Intelligence-CFI/ADeLe-AIEvaluation" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="abstract hidden"> <p>Ensuring safe and effective use of AI requires understanding and anticipating its performance on novel tasks, from advanced scientific challenges to transformed workplace activities. So far, benchmarking has guided progress in AI, but it has offered limited explanatory and predictive power for general-purpose AI systems, given the low transferability across diverse tasks. In this paper, we introduce general scales for AI evaluation that can explain what common AI benchmarks really measure, extract ability profiles of AI systems, and predict their performance for new task instances, in- and out-of-distribution. Our fully-automated methodology builds on 18 newly-crafted rubrics that place instance demands on general scales that do not saturate. Illustrated for 15 large language models and 63 tasks, high explanatory power is unleashed from inspecting the demand and ability profiles, bringing insights on the sensitivity and specificity exhibited by different benchmarks, and how knowledge, metacognition and reasoning are affected by model size, chain-of-thought and distillation. Surprisingly, high predictive power at the instance level becomes possible using these demand levels, providing superior estimates over black-box baseline predictors based on embeddings or finetuning, especially in out-of-distribution settings (new tasks and new benchmarks). The scales, rubrics, battery, techniques and results presented here represent a major step for AI evaluation, underpinning the reliable deployment of AI in the years ahead.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">zhou2025generalscalesunlockai</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{{General Scales Unlock AI Evaluation with Explanatory and Predictive Power}}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Zhou, Lexin and Pacchiardi, Lorenzo and Mart√≠nez-Plumed, Fernando and Collins, Katherine M. and Moros-Daval, Yael and Zhang, Seraphina and Zhao, Qinlin and Huang, Yitian and Sun, Luning and Prunty, Jonathan E. and Li, Zongqian and S√°nchez-Garc√≠a, Pablo and Chen, Kexin Jiang and Casares, Pablo A. M. and Zu, Jiyun and Burden, John and Mehrbakhsh, Behzad and Stillwell, David and Cebrian, Manuel and Wang, Jindong and Henderson, Peter and Wu, Sherry Tongshuang and Kyllonen, Patrick C. and Cheke, Lucy and Xie, Xing and Hern√°ndez-Orallo, Jos√©}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
  <span class="na">eprint</span> <span class="p">=</span> <span class="s">{2503.06378}</span><span class="p">,</span>
  <span class="na">archiveprefix</span> <span class="p">=</span> <span class="s">{arXiv}</span><span class="p">,</span>
  <span class="na">primaryclass</span> <span class="p">=</span> <span class="s">{cs.AI}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{arXiv preprint arXiv:2503.06378}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://kinds-of-intelligence-cfi.github.io/ADELE/}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge">ACL Findings</abbr> </div> <div id="pacchiardi2025predictaboardbenchmarkingllmscore" class="col-sm-8"> <div class="title">PredictaBoard: Benchmarking LLM Score Predictability</div> <div class="author"> <em>Lorenzo Pacchiardi</em> ,¬† Konstantinos Voudouris ,¬† Ben Slater ,¬† Fernando Mart√≠nez-Plumed ,¬† Jos√© Hern√°ndez-Orallo ,¬† Lexin Zhou ,¬† and¬† Wout Schellaert </div> <div class="periodical"> <em>Findings of the Association for Computational Linguistics: ACL 2025</em>, 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://predictaboard.github.io/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="https://github.com/Kinds-of-Intelligence-CFI/PredictaBoard" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="abstract hidden"> <p>Despite possessing impressive skills, Large Language Models (LLMs) often fail unpredictably, demonstrating inconsistent success in even basic common sense reasoning tasks. This unpredictability poses a significant challenge to ensuring their safe deployment, as identifying and operating within a reliable "safe zone" is essential for mitigating risks. To address this, we present PredictaBoard, a novel collaborative benchmarking framework designed to evaluate the ability of score predictors (referred to as assessors) to anticipate LLM errors on specific task instances (i.e., prompts) from existing datasets. PredictaBoard evaluates pairs of LLMs and assessors by considering the rejection rate at different tolerance errors. As such, PredictaBoard stimulates research into developing better assessors and making LLMs more predictable, not only with a higher average performance. We conduct illustrative experiments using baseline assessors and state-of-the-art LLMs. PredictaBoard highlights the critical need to evaluate predictability alongside performance, paving the way for safer AI systems where errors are not only minimised but also anticipated and effectively mitigated.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">pacchiardi2025predictaboardbenchmarkingllmscore</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{{PredictaBoard}: Benchmarking {LLM} Score Predictability}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Pacchiardi, Lorenzo and Voudouris, Konstantinos and Slater, Ben and Mart√≠nez-Plumed, Fernando and Hern√°ndez-Orallo, Jos√© and Zhou, Lexin and Schellaert, Wout}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
  <span class="na">eprint</span> <span class="p">=</span> <span class="s">{2502.14445}</span><span class="p">,</span>
  <span class="na">archiveprefix</span> <span class="p">=</span> <span class="s">{arXiv}</span><span class="p">,</span>
  <span class="na">primaryclass</span> <span class="p">=</span> <span class="s">{cs.CL}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Findings of the Association for Computational Linguistics: ACL 2025}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://predictaboard.github.io/}</span><span class="p">,</span>
  <span class="na">dataset</span> <span class="p">=</span> <span class="s">{https://huggingface.co/collections/kvoudouris/predictaboard-67b6042ee09a99a3b0bbebd0}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge">IJCAI</abbr> </div> <div id="burden2025paradigmsaievaluationmapping" class="col-sm-8"> <div class="title">Paradigms of AI Evaluation: Mapping Goals, Methodologies and Culture</div> <div class="author"> John Burden* ,¬† Marko Te≈°iƒá* ,¬† <em>Lorenzo Pacchiardi*</em> ,¬† and¬† Jos√© Hern√°ndez-Orallo </div> <div class="periodical"> <em>IJCAI 2025 Survey Track</em>, 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://ai-evaluation-paradigms.github.io/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="abstract hidden"> <p>Research in AI evaluation has grown increasingly complex and multidisciplinary, attracting researchers with diverse backgrounds and objectives. As a result, divergent evaluation paradigms have emerged, often developing in isolation, adopting conflicting terminologies, and overlooking each other‚Äôs contributions. This fragmentation has led to insular research trajectories and communication barriers both among different paradigms and with the general public, contributing to unmet expectations for deployed AI systems. To help bridge this insularity, in this paper we survey recent work in the AI evaluation landscape and identify six main paradigms. We characterise major recent contributions within each paradigm across key dimensions related to their goals, methodologies and research cultures. By clarifying the unique combination of questions and approaches associated with each paradigm, we aim to increase awareness of the breadth of current evaluation approaches and foster cross-pollination between different paradigms. We also identify potential gaps in the field to inspire future research directions.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">burden2025paradigmsaievaluationmapping</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Paradigms of {AI} Evaluation: Mapping Goals, Methodologies and Culture}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Burden*, John and Te≈°iƒá*, Marko and Pacchiardi*, Lorenzo and Hern√°ndez-Orallo, Jos√©}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
  <span class="na">eprint</span> <span class="p">=</span> <span class="s">{2502.15620}</span><span class="p">,</span>
  <span class="na">archiveprefix</span> <span class="p">=</span> <span class="s">{arXiv}</span><span class="p">,</span>
  <span class="na">primaryclass</span> <span class="p">=</span> <span class="s">{cs.AI}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{IJCAI 2025 Survey Track}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://arxiv.org/abs/2502.15620}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge">ICLR 2024</abbr> </div> <div id="pacchiardi2023catch" class="col-sm-8"> <div class="title">How to Catch an AI Liar: Lie Detection in Black-Box LLMs by Asking Unrelated Questions</div> <div class="author"> <em>Lorenzo Pacchiardi*</em> ,¬† Alex J Chan* ,¬† S√∂ren Mindermann ,¬† Ilan Moscovitz ,¬† Alexa Y Pan ,¬† Yarin Gal ,¬† Owain Evans ,¬† and¬† Jan Brauner </div> <div class="periodical"> <em>The Twelfth International Conference on Learning Representations</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://openreview.net/forum?id=567BjxgaTp" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="https://github.com/lorypack/llm-liedetector" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="abstract hidden"> <p>Large language models (LLMs) can "lie", which we define as outputting false statements despite "knowing" the truth in a demonstrable sense. LLMs might "lie", for example, when instructed to output misinformation. Here, we develop a simple lie detector that requires neither access to the LLM‚Äôs activations (black-box) nor ground-truth knowledge of the fact in question. The detector works by asking a predefined set of unrelated follow-up questions after a suspected lie, and feeding the LLM‚Äôs yes/no answers into a logistic regression classifier. Despite its simplicity, this lie detector is highly accurate and surprisingly general. When trained on examples from a single setting ‚Äì prompting GPT-3.5 to lie about factual questions ‚Äì the detector generalises out-of-distribution to (1) other LLM architectures, (2) LLMs fine-tuned to lie, (3) sycophantic lies, and (4) lies emerging in real-life scenarios such as sales. These results indicate that LLMs have distinctive lie-related behavioural patterns, consistent across architectures and contexts, which could enable general-purpose lie detection. </p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">pacchiardi2023catch</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{How to Catch an {AI} Liar: Lie Detection in Black-Box {LLM}s by Asking Unrelated Questions}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Pacchiardi*, Lorenzo and Chan*, Alex J and Mindermann, S{\"o}ren and Moscovitz, Ilan and Pan, Alexa Y and Gal, Yarin and Evans, Owain and Brauner, Jan}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{The Twelfth International Conference on Learning Representations}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://openreview.net/forum?id=567BjxgaTp}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> </div> <div class="social"> <div class="contact-icons"> <a href="mailto:%6C%70%36%36%36@%63%61%6D.%61%63.%75%6B" title="email"><i class="fa-solid fa-envelope"></i></a> <a href="https://orcid.org/0000-0003-4760-7638" title="ORCID" rel="external nofollow noopener" target="_blank"><i class="ai ai-orcid"></i></a> <a href="https://scholar.google.com/citations?user=9EAb0uEAAAAJ" title="Google Scholar" rel="external nofollow noopener" target="_blank"><i class="ai ai-google-scholar"></i></a> <a href="https://github.com/LoryPack" title="GitHub" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-github"></i></a> <a href="https://www.linkedin.com/in/lorenzo-pacchiardi" title="LinkedIn" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-linkedin"></i></a> <a href="https://twitter.com/LPacchiardi" title="X" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-x-twitter"></i></a> </div> <div class="contact-note"></div> </div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> ¬© Copyright 2025 Lorenzo Pacchiardi. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. Last updated: December 26, 2025. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script defer src="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.js"></script> <script src="/assets/js/no_defer.js?2930004b8d7fcd0a8e00fdcfc8fc9f24"></script> <script defer src="/assets/js/common.js?4a129fbf39254905f505c7246e641eaf"></script> <script defer src="/assets/js/copy_code.js?7254ae07fe9cc5f3a10843e1c0817c9c" type="text/javascript"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script async src="https://www.googletagmanager.com/gtag/js?id="></script> <script>function gtag(){window.dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","");</script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>